//! Vectorizer Mock Tests for Nexus
//!
//! These tests verify the mock vectorizer implementation and basic integration.

use serde_json::{json, Value};
use std::collections::HashMap;
use std::sync::Arc;
use thiserror::Error;

// ============================================================================
// Mock Vectorizer Implementation
// ============================================================================

/// Trait defining the vectorizer interface
#[async_trait::async_trait]
pub trait Vectorizer {
    /// Perform semantic search
    async fn search(
        &self,
        collection: &str,
        query: &str,
        limit: Option<usize>,
        threshold: Option<f32>,
    ) -> Result<Vec<SearchResult>, VectorizerError>;

    /// Get collection information
    async fn get_collection_info(&self, collection: &str) -> Result<CollectionInfo, VectorizerError>;

    /// List available collections
    async fn list_collections(&self) -> Result<Vec<String>, VectorizerError>;

    /// Index a document
    async fn index_document(
        &self,
        collection: &str,
        document: Document,
    ) -> Result<String, VectorizerError>;

    /// Delete a document
    async fn delete_document(&self, collection: &str, doc_id: &str) -> Result<(), VectorizerError>;
}

/// Search result from vectorizer
#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub struct SearchResult {
    pub id: String,
    pub content: String,
    pub score: f32,
    pub metadata: HashMap<String, Value>,
}

/// Collection information
#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub struct CollectionInfo {
    pub name: String,
    pub document_count: usize,
    pub vector_dimensions: usize,
    pub created_at: String,
}

/// Document to be indexed
#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub struct Document {
    pub id: Option<String>,
    pub content: String,
    pub metadata: HashMap<String, Value>,
}

/// Vectorizer errors
#[derive(Debug, thiserror::Error)]
pub enum VectorizerError {
    #[error("Collection not found: {0}")]
    CollectionNotFound(String),
    #[error("Document not found: {0}")]
    DocumentNotFound(String),
    #[error("Invalid query: {0}")]
    InvalidQuery(String),
    #[error("Indexing error: {0}")]
    IndexingError(String),
    #[error("Network error: {0}")]
    NetworkError(String),
    #[error("Internal error: {0}")]
    InternalError(String),
}

/// Mock vectorizer implementation for testing
pub struct MockVectorizer {
    collections: HashMap<String, Vec<SearchResult>>,
    collection_info: HashMap<String, CollectionInfo>,
    next_doc_id: u64,
}

impl MockVectorizer {
    pub fn new() -> Self {
        let mut vectorizer = Self {
            collections: HashMap::new(),
            collection_info: HashMap::new(),
            next_doc_id: 1,
        };

        // Initialize with some test data
        vectorizer.initialize_test_data();
        vectorizer
    }

    fn initialize_test_data(&mut self) {
        // Create test collection
        let collection_name = "test_collection".to_string();
        
        let test_docs = vec![
            SearchResult {
                id: "doc1".to_string(),
                content: "This is a test document about machine learning".to_string(),
                score: 0.95,
                metadata: {
                    let mut meta = HashMap::new();
                    meta.insert("type".to_string(), Value::String("article".to_string()));
                    meta.insert("author".to_string(), Value::String("Alice".to_string()));
                    meta
                },
            },
            SearchResult {
                id: "doc2".to_string(),
                content: "Graph databases are powerful for relationship queries".to_string(),
                score: 0.87,
                metadata: {
                    let mut meta = HashMap::new();
                    meta.insert("type".to_string(), Value::String("tutorial".to_string()));
                    meta.insert("author".to_string(), Value::String("Bob".to_string()));
                    meta
                },
            },
            SearchResult {
                id: "doc3".to_string(),
                content: "Vector search enables semantic similarity matching".to_string(),
                score: 0.92,
                metadata: {
                    let mut meta = HashMap::new();
                    meta.insert("type".to_string(), Value::String("guide".to_string()));
                    meta.insert("author".to_string(), Value::String("Charlie".to_string()));
                    meta
                },
            },
        ];

        self.collections.insert(collection_name.clone(), test_docs);
        self.collection_info.insert(
            collection_name.clone(),
            CollectionInfo {
                name: collection_name,
                document_count: 3,
                vector_dimensions: 384,
                created_at: "2024-01-01T00:00:00Z".to_string(),
            },
        );

        // Create codebase collection
        let codebase_collection = "codebase".to_string();
        let codebase_docs = vec![
            SearchResult {
                id: "func1".to_string(),
                content: "async fn search_documents(query: &str) -> Result<Vec<Document>>".to_string(),
                score: 0.88,
                metadata: {
                    let mut meta = HashMap::new();
                    meta.insert("file".to_string(), Value::String("src/search.rs".to_string()));
                    meta.insert("function".to_string(), Value::String("search_documents".to_string()));
                    meta.insert("language".to_string(), Value::String("rust".to_string()));
                    meta
                },
            },
            SearchResult {
                id: "func2".to_string(),
                content: "fn create_index(collection: &str) -> Result<Index>".to_string(),
                score: 0.85,
                metadata: {
                    let mut meta = HashMap::new();
                    meta.insert("file".to_string(), Value::String("src/index.rs".to_string()));
                    meta.insert("function".to_string(), Value::String("create_index".to_string()));
                    meta.insert("language".to_string(), Value::String("rust".to_string()));
                    meta
                },
            },
        ];

        self.collections.insert(codebase_collection.clone(), codebase_docs);
        self.collection_info.insert(
            codebase_collection.clone(),
            CollectionInfo {
                name: codebase_collection,
                document_count: 2,
                vector_dimensions: 384,
                created_at: "2024-01-01T00:00:00Z".to_string(),
            },
        );
    }

    fn generate_doc_id(&mut self) -> String {
        let id = self.next_doc_id;
        self.next_doc_id += 1;
        format!("doc{}", id)
    }
}

#[async_trait::async_trait]
impl Vectorizer for MockVectorizer {
    async fn search(
        &self,
        collection: &str,
        query: &str,
        limit: Option<usize>,
        threshold: Option<f32>,
    ) -> Result<Vec<SearchResult>, VectorizerError> {
        let docs = self.collections.get(collection)
            .ok_or_else(|| VectorizerError::CollectionNotFound(collection.to_string()))?;

        let mut results = docs.clone();

        // Apply threshold filter
        if let Some(thresh) = threshold {
            results.retain(|doc| doc.score >= thresh);
        }

        // Sort by score (descending)
        results.sort_by(|a, b| b.score.partial_cmp(&a.score).unwrap_or(std::cmp::Ordering::Equal));

        // Apply limit
        if let Some(limit) = limit {
            results.truncate(limit);
        }

        // Simulate query matching (simplified)
        if !query.is_empty() {
            results.retain(|doc| {
                doc.content.to_lowercase().contains(&query.to_lowercase()) ||
                doc.metadata.values().any(|v| {
                    if let Some(s) = v.as_str() {
                        s.to_lowercase().contains(&query.to_lowercase())
                    } else {
                        false
                    }
                })
            });
        }

        Ok(results)
    }

    async fn get_collection_info(&self, collection: &str) -> Result<CollectionInfo, VectorizerError> {
        self.collection_info.get(collection)
            .cloned()
            .ok_or_else(|| VectorizerError::CollectionNotFound(collection.to_string()))
    }

    async fn list_collections(&self) -> Result<Vec<String>, VectorizerError> {
        Ok(self.collections.keys().cloned().collect())
    }

    async fn index_document(
        &self,
        collection: &str,
        document: Document,
    ) -> Result<String, VectorizerError> {
        // In a real implementation, this would index the document
        // For the mock, we'll just return a generated ID
        let doc_id = document.id.unwrap_or_else(|| {
            // This is a bit hacky, but works for testing
            let mut mock = MockVectorizer::new();
            mock.generate_doc_id()
        });

        Ok(doc_id)
    }

    async fn delete_document(&self, collection: &str, doc_id: &str) -> Result<(), VectorizerError> {
        // In a real implementation, this would delete the document
        // For the mock, we'll just simulate success
        let _ = (collection, doc_id);
        Ok(())
    }
}

// ============================================================================
// Vectorizer Tests
// ============================================================================

#[tokio::test]
async fn test_mock_vectorizer_search() {
    let vectorizer = MockVectorizer::new();
    
    // Test basic search
    let results = vectorizer.search("test_collection", "machine learning", Some(5), Some(0.8)).await.unwrap();
    assert!(!results.is_empty());
    assert_eq!(results[0].id, "doc1");
    assert!(results[0].score >= 0.8);
    
    // Test search with different query
    let results = vectorizer.search("test_collection", "graph", Some(5), Some(0.5)).await.unwrap();
    assert!(!results.is_empty());
    assert!(results.iter().any(|r| r.content.contains("Graph")));
}

#[tokio::test]
async fn test_mock_vectorizer_collections() {
    let vectorizer = MockVectorizer::new();
    
    // Test list collections
    let collections = vectorizer.list_collections().await.unwrap();
    assert!(collections.contains(&"test_collection".to_string()));
    assert!(collections.contains(&"codebase".to_string()));
    
    // Test get collection info
    let info = vectorizer.get_collection_info("test_collection").await.unwrap();
    assert_eq!(info.name, "test_collection");
    assert_eq!(info.document_count, 3);
    assert_eq!(info.vector_dimensions, 384);
}

#[tokio::test]
async fn test_mock_vectorizer_document_operations() {
    let vectorizer = MockVectorizer::new();
    
    // Test index document
    let document = Document {
        id: None,
        content: "This is a new test document".to_string(),
        metadata: {
            let mut meta = HashMap::new();
            meta.insert("type".to_string(), Value::String("test".to_string()));
            meta
        },
    };
    
    let doc_id = vectorizer.index_document("test_collection", document).await.unwrap();
    assert!(!doc_id.is_empty());
    
    // Test delete document
    let result = vectorizer.delete_document("test_collection", &doc_id).await;
    assert!(result.is_ok());
}

#[tokio::test]
async fn test_vectorizer_error_handling() {
    let vectorizer = MockVectorizer::new();
    
    // Test collection not found
    let result = vectorizer.search("nonexistent_collection", "query", Some(5), Some(0.8)).await;
    assert!(matches!(result, Err(VectorizerError::CollectionNotFound(_))));
    
    // Test get collection info for non-existent collection
    let result = vectorizer.get_collection_info("nonexistent_collection").await;
    assert!(matches!(result, Err(VectorizerError::CollectionNotFound(_))));
}

#[tokio::test]
async fn test_vectorizer_concurrent_access() {
    let vectorizer = Arc::new(MockVectorizer::new());
    let mut handles = vec![];
    
    // Spawn multiple concurrent searches
    for i in 0..5 {
        let vectorizer_clone = vectorizer.clone();
        let handle = tokio::spawn(async move {
            let query = format!("concurrent query {}", i);
            vectorizer_clone.search("test_collection", &query, Some(3), Some(0.7)).await
        });
        handles.push(handle);
    }
    
    // Wait for all searches to complete
    let mut success_count = 0;
    for handle in handles {
        match handle.await.unwrap() {
            Ok(_) => success_count += 1,
            Err(e) => println!("Search failed: {:?}", e),
        }
    }
    
    assert_eq!(success_count, 5);
}

#[tokio::test]
async fn test_vectorizer_large_dataset() {
    let vectorizer = MockVectorizer::new();
    
    // Test with larger result set
    let results = vectorizer.search("test_collection", "", Some(100), Some(0.0)).await.unwrap();
    assert_eq!(results.len(), 3); // All documents in test collection
    
    // Test with high threshold (should return fewer results)
    let results = vectorizer.search("test_collection", "", Some(100), Some(0.95)).await.unwrap();
    assert!(results.len() <= 3);
    
    // Test with low threshold (should return all results)
    let results = vectorizer.search("test_collection", "", Some(100), Some(0.0)).await.unwrap();
    assert_eq!(results.len(), 3);
}

#[tokio::test]
async fn test_vectorizer_metadata_filtering() {
    let vectorizer = MockVectorizer::new();
    
    // Search for documents with specific metadata
    let results = vectorizer.search("test_collection", "article", Some(10), Some(0.0)).await.unwrap();
    
    // Should find documents with "article" in metadata
    assert!(!results.is_empty());
    assert!(results.iter().any(|r| {
        r.metadata.get("type")
            .and_then(|v| v.as_str())
            .map(|s| s == "article")
            .unwrap_or(false)
    }));
}

#[tokio::test]
async fn test_vectorizer_codebase_search() {
    let vectorizer = MockVectorizer::new();
    
    // Search in codebase collection
    let results = vectorizer.search("codebase", "search", Some(5), Some(0.8)).await.unwrap();
    
    assert!(!results.is_empty());
    assert!(results.iter().any(|r| r.content.contains("search_documents")));
    
    // Search for specific function
    let results = vectorizer.search("codebase", "create_index", Some(5), Some(0.8)).await.unwrap();
    
    assert!(!results.is_empty());
    assert!(results.iter().any(|r| r.content.contains("create_index")));
}

#[tokio::test]
async fn test_hybrid_search_simulation() {
    let vectorizer = MockVectorizer::new();
    
    // Simulate hybrid search: graph traversal + vectorizer search
    let query = "machine learning";
    
    // 1. Graph traversal (simulated)
    let graph_results = vec![
        json!({
            "node_id": "node1",
            "label": "Algorithm",
            "properties": {
                "name": "Random Forest",
                "type": "ensemble"
            }
        }),
        json!({
            "node_id": "node2", 
            "label": "Algorithm",
            "properties": {
                "name": "Neural Network",
                "type": "deep_learning"
            }
        })
    ];
    
    // 2. Vectorizer semantic search
    let vectorizer_results = vectorizer.search("test_collection", query, Some(5), Some(0.7)).await.unwrap();
    
    // 3. Combine results (simplified RRF)
    let mut combined_results = Vec::new();
    
    // Add graph results
    for (i, result) in graph_results.iter().enumerate() {
        combined_results.push(json!({
            "source": "graph",
            "rank": i + 1,
            "data": result
        }));
    }
    
    // Add vectorizer results
    for (i, result) in vectorizer_results.iter().enumerate() {
        combined_results.push(json!({
            "source": "vectorizer",
            "rank": i + 1,
            "score": result.score,
            "data": {
                "id": result.id,
                "content": result.content,
                "metadata": result.metadata
            }
        }));
    }
    
    // Verify combined results
    assert!(!combined_results.is_empty());
    assert!(combined_results.iter().any(|r| r["source"] == "graph"));
    assert!(combined_results.iter().any(|r| r["source"] == "vectorizer"));
}

#[tokio::test]
async fn test_vectorizer_performance_metrics() {
    let vectorizer = MockVectorizer::new();
    
    let start = std::time::Instant::now();
    
    // Perform multiple searches
    for i in 0..10 {
        let query = format!("test query {}", i);
        let _results = vectorizer.search("test_collection", &query, Some(5), Some(0.8)).await.unwrap();
    }
    
    let elapsed = start.elapsed();
    println!("Performed 10 searches in {:?}", elapsed);
    
    // Should be fast (under 1 second for 10 searches)
    assert!(elapsed.as_secs() < 1);
}

#[tokio::test]
async fn test_vectorizer_error_propagation() {
    let vectorizer = MockVectorizer::new();
    
    // Test various error conditions
    let error_cases = vec![
        ("nonexistent_collection", "query", "CollectionNotFound"),
    ];
    
    for (collection, query, expected_error) in error_cases {
        let result = vectorizer.search(collection, query, Some(5), Some(0.8)).await;
        
        match result {
            Err(VectorizerError::CollectionNotFound(_)) if expected_error == "CollectionNotFound" => {
                // Expected error
            }
            Ok(_) => {
                panic!("Expected error {} but got success", expected_error);
            }
            Err(e) => {
                panic!("Expected error {} but got: {:?}", expected_error, e);
            }
        }
    }
}