# Nexus Architecture

Nexus is a high-performance property graph database designed for read-heavy workloads with native vector search integration. It implements a Neo4j-inspired storage architecture with Cypher subset query language, optimized for KNN-seeded graph traversal.

## Design Philosophy

1. **Property Graph Model**: Nodes with labels, relationships with types, both carrying properties
2. **Read Optimized**: Record stores with linked lists for O(1) traversal without index lookups
3. **Vector Native**: First-class KNN support via HNSW indexes per label
4. **Simple Transactions**: MVCC via epochs, single-writer for predictability
5. **Append-Only**: Immutable record architecture with periodic compaction

## System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        REST/HTTP API                             â”‚
â”‚            (Cypher, KNN Traverse, Bulk Ingest)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Cypher Executor                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚  Parser  â”‚â†’ â”‚ Planner  â”‚â†’ â”‚Operators â”‚â†’ â”‚ Results  â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚         Pattern Match â€¢ Expand â€¢ Filter â€¢ Project               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Transaction Layer                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚  MVCC (Epochs)   â”‚         â”‚ Locking (Queues) â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Index Layer                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ Label   â”‚  â”‚ B-tree  â”‚  â”‚Tantivy   â”‚  â”‚  HNSW    â”‚         â”‚
â”‚  â”‚ Bitmap  â”‚  â”‚(Props)  â”‚  â”‚(FullText)â”‚  â”‚  (KNN)   â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Storage Layer                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚  Catalog â”‚  â”‚   WAL    â”‚  â”‚  Record  â”‚  â”‚   Page   â”‚       â”‚
â”‚  â”‚  (LMDB)  â”‚  â”‚ (AppendJ)â”‚  â”‚  Stores  â”‚  â”‚  Cache   â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚   Labels/Keys    Durability   Nodes/Rels    Memory Mgmt        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Storage Layer

### Record Stores (Neo4j-Inspired)

Fixed-size record architecture for predictable performance:

#### nodes.store

```
NodeRecord (32 bytes):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ label_bits   â”‚ first_rel_ptrâ”‚  prop_ptr    â”‚   flags      â”‚
â”‚   (8 bytes)  â”‚  (8 bytes)   â”‚  (8 bytes)   â”‚  (8 bytes)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

- label_bits: Bitmap of label IDs (supports 64 labels per node)
- first_rel_ptr: Head of doubly-linked relationship list
- prop_ptr: Pointer to property chain
- flags: Deleted, locked, version bits
```

#### rels.store

```
RelationshipRecord (48 bytes):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  src_id â”‚ dst_id  â”‚ type_id â”‚next_src_ptrâ”‚next_dst_ptrâ”‚ prop_ptr â”‚ flags  â”‚
â”‚(8 bytes)â”‚(8 bytes)â”‚(4 bytes)â”‚  (8 bytes) â”‚  (8 bytes) â”‚(8 bytes) â”‚(4 bytes)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜

- Doubly-linked lists: next_src_ptr (outgoing from src), next_dst_ptr (incoming to dst)
- Enables O(1) traversal without index lookups
```

#### props.store

```
PropertyRecord (Variable):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  key_id  â”‚  type    â”‚  value   â”‚ next_ptr â”‚
â”‚(4 bytes) â”‚(1 byte)  â”‚ (varies) â”‚(8 bytes) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

- Chain of properties per entity
- Small values inline, large values in strings.store
- Types: null, bool, int64, float64, string_ref, bytes_ref
```

#### strings.store

```
String/Blob Dictionary:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ varint_len   â”‚    data      â”‚    crc32     â”‚  padding â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

- Deduplicated string/blob storage
- CRC32 for corruption detection
- Reference counted for garbage collection
```

### Catalog (LMDB via heed)

Bidirectional mappings stored in embedded key-value store:

```
Tables:
- label_name â†’ label_id
- label_id â†’ label_name
- type_name â†’ type_id
- type_id â†’ type_name
- key_name â†’ key_id
- key_id â†’ key_name

Metadata:
- Statistics (node count per label, relationship count per type)
- Schema constraints (UNIQUE, NOT NULL)
- Index definitions
```

### Page Cache

4-8KB pages with eviction policies:

```
Page Structure:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ page_id  â”‚ checksum â”‚   data   â”‚  flags   â”‚
â”‚(8 bytes) â”‚(4 bytes) â”‚(varies)  â”‚(4 bytes) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Eviction Policies:
- Clock: Simple second-chance algorithm
- 2Q: Hot/cold queue split
- TinyLFU: Frequency + recency estimation

Pin/Unpin Semantics:
- Pinned pages cannot be evicted (active transactions)
- Dirty pages flushed on checkpoint
- xxHash3 checksums for validation
```

### Write-Ahead Log (WAL)

Append-only transaction log:

```
WAL Entry Format:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  epoch   â”‚  tx_id   â”‚  type    â”‚ payload  â”‚  crc32   â”‚
â”‚(8 bytes) â”‚(8 bytes) â”‚(1 byte)  â”‚(varies)  â”‚(4 bytes) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Entry Types:
- BEGIN_TX, COMMIT_TX, ABORT_TX
- CREATE_NODE, DELETE_NODE
- CREATE_REL, DELETE_REL
- SET_PROPERTY, DELETE_PROPERTY
- CHECKPOINT

Checkpointing:
1. Freeze current epoch
2. Flush all dirty pages
3. Write CHECKPOINT entry
4. Truncate old WAL segments
5. Run compactor on record stores
```

## Transaction Layer

### MVCC via Epochs

```
Epoch-Based Snapshots:
- Global epoch counter (atomic u64)
- Readers pin an epoch (snapshot isolation)
- Writers increment epoch on commit
- Garbage collection removes old versions

Visibility Rules:
- Record visible if: created_epoch â‰¤ tx_epoch < deleted_epoch
- Append-only: new versions append, old kept until GC
```

### Locking Strategy

```
Single-Writer per Partition (MVP):
- Hash(node_id) â†’ partition_id
- Queue per partition (FIFO)
- Group commit: batch small writes

Future (V2):
- Intent locks (read/write)
- Deadlock detection via wait-for graph
```

## Index Layer

### Label Bitmap Index

```
RoaringBitmap per Label:
label_id â†’ RoaringBitmap<node_id>

- Compressed bitmap (runs, arrays, bitmaps)
- Fast AND/OR/NOT for label filtering
- Cardinality estimates for planner
```

### Property B-tree Index (V1)

```
Composite Key: (label_id, key_id, value) â†’ [node_ids]

- Range queries: WHERE n.age > 18
- Equality: WHERE n.email = "user@example.com"
- Statistics: NDV (number distinct values), histograms
```

### Full-Text Index (V1)

```
Tantivy Index per (label, key):

- Inverted index with positions
- BM25 scoring
- Fuzzy search, phrase queries
- Procedure: CALL text.search('Person', 'bio', 'engineer')
```

### KNN Vector Index (MVP)

```
HNSW Index per Label:

File: hnsw_<label_id>.bin
Mapping: node_id â†’ embedding_idx

- HNSW (Hierarchical Navigable Small World)
- Cosine similarity or Euclidean distance
- Configurable ef_construction, M parameters
- Procedure: CALL vector.knn('Person', $embedding, 10)
```

## Executor Layer

### Cypher Subset

Supported syntax (20% covering 80% use cases):

```cypher
-- Pattern matching
MATCH (n:Person)-[r:KNOWS]->(m:Person)
WHERE n.age > 25 AND m.city = 'NYC'
RETURN n.name, m.name, r.since
ORDER BY r.since DESC
LIMIT 100

-- KNN-seeded traversal
CALL vector.knn('Person', $embedding, 10) YIELD node AS n
MATCH (n)-[:WORKS_AT]->(c:Company)
RETURN n.name, c.name

-- Aggregations
MATCH (p:Person)-[:LIKES]->(product:Product)
RETURN product.category, COUNT(*) AS likes
ORDER BY likes DESC
```

### Physical Operators

```
Operator Pipeline:

1. NodeByLabel(label_id)
   â†’ Scan label bitmap
   â†’ Output: stream of node_ids

2. Filter(predicate)
   â†’ Apply property filters
   â†’ Vectorized evaluation (SIMD where possible)

3. Expand(type_id, direction)
   â†’ Follow linked lists (next_src_ptr/next_dst_ptr)
   â†’ Direction: OUT, IN, BOTH

4. Project(expressions)
   â†’ Evaluate return expressions
   â†’ Property access, functions

5. OrderBy(keys) + Limit(n)
   â†’ Top-K heap for efficiency
   â†’ Partial sort when LIMIT present

6. Aggregate(group_keys, agg_funcs)
   â†’ Hash aggregation
   â†’ COUNT, SUM, AVG, MIN, MAX, COLLECT
```

### Query Planner

```
Heuristic Cost-Based:

Statistics Used:
- |V_label|: Node count per label
- |E_type|: Relationship count per type
- avg_degree(label, type): Average out-degree
- NDV(label, key): Number distinct values

Optimization Rules:
1. Push filters down (early elimination)
2. Reorder patterns by selectivity (smallest first)
3. Index selection (label vs property vs KNN)
4. Limit pushdown for top-K queries

Example:
MATCH (a:Rare)-[:TYPE1]->(b:Common)-[:TYPE2]->(c)
â†’ Start with Rare (smaller cardinality)
â†’ Expand to Common, filter early
```

## Integration Layer

### StreamableHTTP API (Default Protocol)

**Primary protocol** following Vectorizer implementation:

```
Default Transport: StreamableHTTP
- Chunked transfer encoding for large result sets
- Server-Sent Events (SSE) for streaming
- HTTP/2 multiplexing and flow control
- Efficient for both small and large responses

Endpoints:

POST /cypher
{
  "query": "MATCH (n:Person) RETURN n LIMIT 10",
  "params": {"name": "Alice"}
}

POST /knn_traverse
{
  "label": "Person",
  "vector": [0.1, 0.2, ...],
  "k": 10,
  "expand": ["(n)-[:KNOWS]->(m)"],
  "where": "m.age > 25",
  "limit": 100
}

POST /ingest
{
  "nodes": [
    {"labels": ["Person"], "properties": {"name": "Alice", "age": 30}}
  ],
  "relationships": [
    {"src": 1, "dst": 2, "type": "KNOWS", "properties": {"since": 2020}}
  ]
}

Streaming Response (SSE):
event: row
data: {"node": {...}, "score": 0.95}

event: row
data: {"node": {...}, "score": 0.92}

event: complete
data: {"total": 100, "execution_time_ms": 15}
```

### MCP Protocol Integration

**Model Context Protocol** for AI integrations (Vectorizer-style):

```
MCP Tools (19+ focused tools):
- nexus/query - Execute Cypher queries
- nexus/knn_search - KNN vector search
- nexus/pattern_match - Graph pattern matching
- nexus/ingest_node - Create single node
- nexus/ingest_relationship - Create relationship
- nexus/get_schema - Get graph schema
- nexus/get_stats - Database statistics
- ... (expandable)

Benefits:
- Reduced entropy (no enum parameters)
- Tool-specific parameters only
- Better model tool calling accuracy
```

### UMICP Protocol Integration

**Universal Model Interoperability Protocol** following Vectorizer v0.2.1:

```
UMICP Features:
- Native JSON types support
- Tool Discovery endpoint: GET /umicp/discover
- Exposes all MCP tools with full schemas
- Cross-service graph queries
- Event-driven graph updates

Discovery Response:
{
  "service": "nexus-graph",
  "version": "0.1.0",
  "protocol": "UMICP/0.2.1",
  "tools": [
    {
      "name": "graph.query",
      "description": "Execute Cypher query",
      "inputSchema": {...}
    }
  ]
}
```

### Vectorizer Integration (Native)

**Direct integration** with Vectorizer for hybrid search:

```
Integration Modes:

1. Embedding Generation:
   POST /vectorizer/embed â†’ vector
   Store vector in Nexus KNN index

2. Hybrid Search:
   Nexus KNN search â†’ node_ids
   Vectorizer semantic search â†’ enhanced relevance
   Combined ranking via Reciprocal Rank Fusion (RRF)

3. Bidirectional Sync:
   Vectorizer change â†’ Nexus graph update (relationship creation)
   Nexus mutation â†’ Vectorizer re-index (embedding update)

Example Flow:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      embed()      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Vectorizer â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚   Nexus    â”‚
â”‚            â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º  â”‚            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   vector result   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                                â”‚
      â”‚ semantic search                â”‚ graph traversal
      â–¼                                â–¼
   Relevance scores              Relationship context
      â”‚                                â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
              Combined Results
           (RRF ranking algorithm)
```

## Performance Characteristics

### Read Performance

```
- Node lookup by ID: O(1) - direct offset
- Expand neighbors: O(degree) - linked list traversal
- Pattern match: O(|V_start| Ã— selectivity Ã— expansions)
- KNN search: O(log N) - HNSW logarithmic
- Full scan: O(|V|) - bitmap scan

Target Throughput (Single Node):
- Point reads: 100K+ ops/sec
- KNN queries: 10K+ ops/sec
- Pattern traversal: 1K-10K ops/sec (depth dependent)
```

### Write Performance

```
- Insert node: O(1) - append to nodes.store
- Insert relationship: O(1) - append + update pointers
- Update property: O(props_per_entity) - traverse chain
- Bulk ingest: Batch via WAL, bypass cache

Target Throughput (Single Writer):
- Inserts: 10K-50K ops/sec
- Updates: 5K-20K ops/sec
- Bulk load: 100K+ nodes/sec (direct store generation)
```

### Space Overhead

```
Per Node: ~32 bytes (record) + properties + index entries
Per Relationship: ~48 bytes + properties
Property: ~16 bytes + value size
Index Overhead:
- Label bitmap: ~0.1-1 byte per node (compressed)
- HNSW vector: ~100-200 bytes per vector (M=16)

Example (1M nodes, 2M relationships, avg 5 props):
- Nodes: 32MB
- Relationships: 96MB
- Properties: ~160MB (assuming 20 bytes avg per prop)
- Indexes: ~50MB (bitmaps + HNSW)
Total: ~340MB (reasonable)
```

## Authentication & Security

### API Key Authentication

**Vectorizer-style authentication** with flexible configuration:

```
Configuration:
- Default: Authentication DISABLED (localhost development)
- Production: REQUIRED when binding to 0.0.0.0 (public interface)
- API Keys: 32-character random strings
- Storage: Hashed with Argon2 in catalog (LMDB)

AuthConfig:
{
  "enabled": false,                    // Default: disabled for localhost
  "require_for_public_bind": true,     // Force enable for 0.0.0.0
  "api_key_length": 32,
  "rate_limit_per_minute": 1000,
  "rate_limit_per_hour": 10000,
  "jwt_secret": "change-in-production",
  "jwt_expiration": 3600
}

API Key Format:
{
  "id": "key_abc123",
  "name": "Production App",
  "key_hash": "argon2id$...",
  "user_id": "admin",
  "permissions": ["read", "write", "admin"],
  "created_at": 1704067200,
  "expires_at": null,  // Never expires
  "active": true
}

Usage:
Authorization: Bearer nexus_sk_abc123...xyz

Rate Limiting:
- 1000 requests/minute per API key
- 10000 requests/hour per API key
- 429 Too Many Requests on exceed
- X-RateLimit-* headers in response
```

### Security Model (V1)

```
Permissions:
- READ: Query execution (MATCH, CALL vector.knn)
- WRITE: Data mutations (CREATE, SET, DELETE)
- ADMIN: Index management, constraints, schema changes
- SUPER: Replication, cluster management

Role-Based Access Control (RBAC):
- User â†’ Roles â†’ Permissions
- API Key â†’ Permissions (direct)
- JWT tokens for session management
- Audit logging for all write operations

Transport Security:
- TLS 1.3 for production (via Axum/Tower)
- mTLS for service-to-service (V2)
- Certificate-based authentication (optional)
```

## Replication System (V1)

### Master-Replica Architecture

**Inspired by Redis/Vectorizer replication** with graph-specific optimizations:

```
Topology:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Master Node   â”‚â”€â”€â”€â”€â”€â”€â”€â”€>â”‚ Replica Node 1 â”‚
â”‚  (Read+Write)  â”‚         â”‚  (Read-Only)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚ Replica Node 2 â”‚
                           â”‚  (Read-Only)   â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Replication Flow:
1. Master receives write
2. Append to WAL
3. Apply to local storage
4. Stream WAL entry to replicas
5. Replicas apply + ACK
6. Master commits transaction
```

### Replication Modes

```
1. Full Sync (Initial):
   - Master creates snapshot
   - Transfer snapshot.tar.zst to replica
   - CRC32 checksum verification
   - Replica loads snapshot
   - Switch to incremental sync

2. Incremental Sync:
   - Stream WAL entries to replicas
   - Circular replication log (1M operations)
   - Auto-reconnect with exponential backoff
   - Lag monitoring and alerts

3. Async Replication:
   - Master doesn't wait for replica ACK (default)
   - Higher throughput, eventual consistency
   - Configurable ACK timeout

4. Sync Replication (optional):
   - Wait for N replicas to ACK
   - Lower throughput, stronger durability
   - Configurable quorum
```

### Replication Protocol

```
WAL Streaming:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Master WAL Entry                     â”‚
â”‚  {epoch, tx_id, type, payload, crc}  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ TCP stream
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Replica Receiver                     â”‚
â”‚  - Validate CRC                       â”‚
â”‚  - Apply to local WAL                 â”‚
â”‚  - Update storage                     â”‚
â”‚  - Send ACK                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

REST API Endpoints:
- GET  /replication/status
- POST /replication/promote   (replica â†’ master)
- POST /replication/pause
- POST /replication/resume
- GET  /replication/lag       (replication lag in seconds)
```

### Failover & High Availability

```
Automatic Failover (V1):
1. Monitor master health (heartbeat every 5s)
2. Detect master failure (3 missed heartbeats)
3. Elect new master (manual or via consensus)
4. Promote replica: POST /replication/promote
5. Redirect clients to new master
6. Old master rejoins as replica (when recovered)

Manual Failover:
curl -X POST http://replica:15474/replication/promote \
  -H "Authorization: Bearer admin_key"
```

## Sharding & Distribution (V2)

### Sharding Strategy

**Hash-based partitioning** for horizontal scalability:

```
Shard Assignment:
shard_id = hash(node_id) % num_shards

Example (4 shards):
- Shard 0: node_ids where hash % 4 == 0
- Shard 1: node_ids where hash % 4 == 1
- Shard 2: node_ids where hash % 4 == 2
- Shard 3: node_ids where hash % 4 == 3

Relationship Placement:
- Relationships reside with source node
- Cross-shard edges stored as remote pointers
- Minimize cross-shard hops in queries

Topology:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Shard 0    â”‚  â”‚   Shard 1    â”‚  â”‚   Shard 2    â”‚
â”‚  (Master)    â”‚  â”‚  (Master)    â”‚  â”‚  (Master)    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                 â”‚                 â”‚
   â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”
   â”‚Replica1â”‚        â”‚Replica1â”‚        â”‚Replica1â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Distributed Queries

```
Query Coordinator:
1. Parse Cypher query
2. Identify required shards (WHERE clause analysis)
3. Decompose plan into shard-local subplans
4. Execute in parallel (scatter)
5. Merge results (gather)
6. Apply global ORDER BY + LIMIT

Optimizations:
- Pushdown filters to shards
- Pushdown LIMIT (top-K per shard)
- Minimize data transfer
- Cache remote node metadata

Cross-Shard Traversal:
MATCH (n:Person)-[:KNOWS]->(m:Person)
â†’ If n and m on different shards:
  1. Execute on n's shard
  2. Fetch m's metadata remotely
  3. Continue traversal
  4. Cache cross-shard edges
```

### Consensus & Coordination

```
Raft Consensus (via openraft):
- One Raft group per shard
- Leader handles all writes
- Followers replicate via Raft log
- Strong consistency per shard
- Eventual consistency cross-shard

Shard Metadata (in catalog):
{
  "shard_id": 0,
  "leader": "node1:15474",
  "followers": ["node2:15474", "node3:15474"],
  "status": "healthy",
  "node_count": 250000,
  "rel_count": 500000
}
```

## Desktop GUI (Electron)

### Overview

**Modern desktop application** for visual graph management and exploration:

```
Technology Stack:
- Electron (cross-platform desktop)
- Vue 3 + Composition API
- TailwindCSS (styling)
- D3.js / Cytoscape.js (graph visualization)
- Chart.js (metrics)

Features:
ğŸ¨ Beautiful interface with dark/light themes
ğŸ“Š Real-time graph visualization (force-directed layout)
ğŸ” Visual Cypher query builder
âš¡ Live query execution with syntax highlighting
ğŸ“ˆ Database metrics and monitoring
ğŸ’¾ Backup/restore operations
ğŸ”§ Configuration editor
ğŸ“ Schema browser (labels, types, properties)
ğŸ¯ KNN vector search interface
```

### GUI Capabilities

```
1. Graph Visualization:
   - Force-directed graph layout
   - Node filtering by label
   - Relationship filtering by type
   - Property inspector
   - Zoom, pan, node selection

2. Query Interface:
   - Cypher editor with syntax highlighting
   - Query history
   - Result table/graph view toggle
   - Export results (JSON, CSV)
   - Saved queries

3. Schema Management:
   - View all labels and types
   - Property statistics
   - Index management
   - Constraint creation/deletion

4. KNN Vector Search:
   - Text input â†’ generate embedding
   - Visual similarity search results
   - Hybrid query builder (KNN + patterns)
   - Vector index management

5. Database Operations:
   - Backup/restore
   - Import/export data
   - Replication monitoring
   - Performance metrics
   - Log viewer

6. Monitoring Dashboard:
   - Query throughput
   - Page cache hit rate
   - WAL size
   - Replication lag
   - Index sizes
```

### Installation & Usage

```bash
# Development
cd gui
npm install
npm run dev

# Build installers
npm run build:win     # Windows MSI
npm run build:mac     # macOS DMG
npm run build:linux   # Linux AppImage/DEB

# Run packaged app
./dist/Nexus-Setup-0.1.0.exe       # Windows
./dist/Nexus-0.1.0.dmg             # macOS
./dist/nexus_0.1.0_amd64.AppImage  # Linux
```

### GUI Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Electron Main Process          â”‚
â”‚  - Window management                    â”‚
â”‚  - Auto-updater                         â”‚
â”‚  - File system access                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚ IPC
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Electron Renderer Process        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Vue 3 Application                 â”‚ â”‚
â”‚  â”‚  - Graph Visualization (Cytoscape) â”‚ â”‚
â”‚  â”‚  - Query Editor (CodeMirror)       â”‚ â”‚
â”‚  â”‚  - Dashboard (Chart.js)            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚ HTTP/WebSocket
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Nexus Server (Axum)              â”‚
â”‚    http://localhost:15474                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Scalability Path

### V1: Single Node Optimization

- Batch optimizations (vectorization, SIMD)
- Advanced indexes (B-tree, full-text)
- Query cache (prepared statements)
- Read replicas (WAL streaming)

### V2: Distributed Graph

```
Sharding Strategy:
- Hash(node_id) â†’ shard_id
- Relationships reside with source node
- Cross-shard edges via remote pointers

Replication:
- Raft consensus per shard (openraft)
- Leader handles writes, followers serve reads
- Causal consistency via vector clocks

Distributed Queries:
- Coordinator decomposes plan
- Pushdown filters/limits to shards
- Scatter/gather with streaming results
- Minimize cross-shard hops
```

## Comparison with Neo4j

| Feature | Neo4j | Nexus |
|---------|-------|-------|
| Storage | Record stores + page cache | Same approach |
| Query Language | Full Cypher | Cypher subset (20%) |
| Transactions | ACID, full MVCC | Simplified MVCC (epochs) |
| Indexes | B-tree, full-text, native | Same + native KNN (HNSW) |
| Clustering | Causal cluster | Future (openraft) |
| Vector Search | Plugin (GDS) | Native first-class |
| Target Workload | General graph | Read-heavy + RAG |

## Future Enhancements

- **Temporal Graph**: Valid-time versioning for time-travel queries
- **Geospatial**: PostGIS-like spatial indexes and functions
- **Graph Algorithms**: Native BFS, DFS, PageRank, community detection
- **Streaming Ingestion**: Kafka/Pulsar integration
- **Advanced Analytics**: Integration with Apache Arrow for OLAP

## References

- Neo4j Internals: https://neo4j.com/docs/operations-manual/current/
- HNSW Algorithm: https://arxiv.org/abs/1603.09320
- MVCC in Databases: Postgres, CockroachDB documentation
- Roaring Bitmaps: https://roaringbitmap.org/
- Tantivy: https://github.com/quickwit-oss/tantivy

